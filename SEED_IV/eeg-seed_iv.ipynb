{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import scipy\n",
    "import os\n",
    "from os import listdir\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 210820527211751965\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 201488586902541489\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "set_session(sess)\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/eeg_feature_smooth/1/', './data/eeg_feature_smooth/2/', './data/eeg_feature_smooth/3/']\n"
     ]
    }
   ],
   "source": [
    "directory = \"./data/eeg_feature_smooth/1/\"\n",
    "directories = [\"./data/eeg_feature_smooth/{}/\".format(i+1) for i in range(3)] \n",
    "print(directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/eeg_feature_smooth/1/\n",
      "./data/eeg_feature_smooth/2/\n",
      "./data/eeg_feature_smooth/3/\n",
      "(3, 15, 24, 4, 62, 5, 64)\n"
     ]
    }
   ],
   "source": [
    "n = 24\n",
    "perSample = ['de_movingAve', 'de_LDS', 'psd_movingAve', 'psd_LDS']\n",
    "array = np.zeros(shape=(len(directories),len(os.listdir(directories[0])), n, 4, 62, 5, 64)) # features = 4*62*5*64 (zero padded) // trials = (3 sessions) x 15 people x 24 labels \n",
    "li = []\n",
    "for h, dire in enumerate(directories):\n",
    "    print(dire)\n",
    "    data = [loadmat(dire + file) for file in os.listdir(dire)]\n",
    "    for i, bigsample in enumerate(data):\n",
    "        for j in range(n):\n",
    "            for k, key in enumerate(perSample):\n",
    "                sample = np.transpose(np.array(bigsample[key + str(j+1)]), (0,2,1))\n",
    "                #print(sample.shape)\n",
    "                sample = np.pad(sample, [(0,0), (0,0), (0, 64-sample.shape[2])])\n",
    "                #print(sample.shape)\n",
    "                array[h][i][j][k] = sample\n",
    "\n",
    "print(array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = array.reshape(np.prod(array.shape[0:3]), *array.shape[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 4, 62, 5, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session1_label = [1,2,3,0,2,0,0,1,0,1,2,1,1,1,2,3,2,2,3,3,0,3,0,3]\n",
    "session2_label = [2,1,3,0,0,2,0,2,3,3,2,3,2,0,1,1,2,1,0,3,0,1,3,1]\n",
    "session3_label = [1,2,2,1,3,3,3,1,1,2,1,0,2,3,3,0,2,3,0,0,2,0,1,0]\n",
    "labels = {0: 'neutral', 1: 'sad', 2: 'fear', 3: 'happy'}\n",
    "\n",
    "y = np.array(session1_label * 15 + session2_label * 15 + session3_label * 15)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 4, 62, 5)\n",
      "(1080, 64, 1240)\n"
     ]
    }
   ],
   "source": [
    "X = _X.transpose(0, 4, 1, 2,3)\n",
    "print(X.shape)\n",
    "X = X.reshape(X.shape[0], X.shape[1], np.prod(X.shape[2:]))\n",
    "print(X.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_conv():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='elu',input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.Conv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='elu',input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.Conv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='elu',input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.Conv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='elu',input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_conv():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(\n",
    "32, 3, activation='relu',input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 64, 128)           476288    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8, 128)            49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 691,082\n",
      "Trainable params: 691,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = fully_conv()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 864 samples\n",
      "Epoch 1/30\n",
      "864/864 [==============================] - 9s 10ms/sample - loss: 89274830.5185 - accuracy: 0.2512\n",
      "Epoch 2/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 18615162.0729 - accuracy: 0.3056\n",
      "Epoch 3/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 2942563.5700 - accuracy: 0.3762\n",
      "Epoch 4/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 4837033.5615 - accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 8163885.8895 - accuracy: 0.3264\n",
      "Epoch 6/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 3525689.0739 - accuracy: 0.2917\n",
      "Epoch 7/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 64795668.7729 - accuracy: 0.3102\n",
      "Epoch 8/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 4502404.3906 - accuracy: 0.3611\n",
      "Epoch 9/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 11551491.4693 - accuracy: 0.2975\n",
      "Epoch 10/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 2376007.5987 - accuracy: 0.3322\n",
      "Epoch 11/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 1879364.9385 - accuracy: 0.3530\n",
      "Epoch 12/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 774381.4362 - accuracy: 0.3924\n",
      "Epoch 13/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 1285693.7101 - accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 92745.1387 - accuracy: 0.3681\n",
      "Epoch 15/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 55049.4159 - accuracy: 0.3773\n",
      "Epoch 16/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 44023.9394 - accuracy: 0.3831\n",
      "Epoch 17/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 35645.3453 - accuracy: 0.4074\n",
      "Epoch 18/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 84212.1066 - accuracy: 0.4109\n",
      "Epoch 19/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 174826.7394 - accuracy: 0.3785\n",
      "Epoch 20/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 71683.3749 - accuracy: 0.4144\n",
      "Epoch 21/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 33131.1504 - accuracy: 0.4699\n",
      "Epoch 22/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 48765.5286 - accuracy: 0.4711\n",
      "Epoch 23/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 28087.3884 - accuracy: 0.4630\n",
      "Epoch 24/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 22638.6095 - accuracy: 0.4919\n",
      "Epoch 25/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 18851.4995 - accuracy: 0.5208\n",
      "Epoch 26/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 16511.6501 - accuracy: 0.5463\n",
      "Epoch 27/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 14764.6982 - accuracy: 0.5602\n",
      "Epoch 28/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 13549.6211 - accuracy: 0.5694\n",
      "Epoch 29/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 12363.7023 - accuracy: 0.5822\n",
      "Epoch 30/30\n",
      "864/864 [==============================] - 3s 4ms/sample - loss: 11921.8812 - accuracy: 0.5845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aaafa8d3410>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/1 - 0s - loss: 14577868.5267 - accuracy: 0.4491\n",
      "\n",
      "Test accuracy: 0.44907406\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:2019.10]",
   "language": "python",
   "name": "conda-env-2019.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
