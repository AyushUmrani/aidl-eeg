{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import scipy\n",
    "import os\n",
    "from os import listdir\n",
    "from scipy.io import loadmat\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4046803580047596474\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12958402281358943626\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 571743436001025966\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7009469728\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17402970460495430772\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "set_session(sess)\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/eeg_feature_smooth/1/', './data/eeg_feature_smooth/2/', './data/eeg_feature_smooth/3/']\n",
      "8 9\n",
      "{0: (0, 3), 1: (0, 4), 2: (0, 5), 3: (0, 2), 4: (0, 6), 5: (1, 0), 6: (1, 1), 7: (1, 2), 8: (1, 3), 9: (1, 4), 10: (1, 5), 11: (1, 6), 12: (1, 7), 13: (1, 8), 14: (2, 0), 15: (2, 1), 16: (2, 2), 17: (2, 3), 18: (2, 4), 19: (2, 5), 20: (2, 6), 21: (2, 7), 22: (2, 8), 23: (3, 0), 24: (3, 1), 25: (3, 2), 26: (3, 3), 27: (3, 4), 28: (3, 5), 29: (3, 6), 30: (3, 7), 31: (3, 8), 32: (4, 0), 33: (4, 1), 34: (4, 2), 35: (4, 3), 36: (4, 4), 37: (4, 5), 38: (4, 6), 39: (4, 7), 40: (4, 8), 41: (5, 0), 42: (5, 1), 43: (5, 2), 44: (5, 3), 45: (5, 4), 46: (5, 5), 47: (5, 6), 48: (5, 7), 49: (5, 8), 50: (6, 1), 51: (6, 2), 52: (6, 3), 53: (6, 4), 54: (6, 5), 55: (6, 6), 56: (6, 7), 57: (7, 2), 58: (7, 3), 59: (7, 4), 60: (7, 5), 61: (7, 6)}\n"
     ]
    }
   ],
   "source": [
    "directory = \"./data/eeg_feature_smooth/1/\"\n",
    "directories = [\"./data/eeg_feature_smooth/{}/\".format(i+1) for i in range(3)] \n",
    "print(directories)\n",
    "channel_coords = [['0', '0', 'AF3', 'FP1', 'FPZ', 'FP2', 'AF4', '0', '0'], ['F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8'], ['FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8'], ['T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8'], ['TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8'], ['P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8'], ['0', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', '0'], ['0', '0', 'CB1', 'O1', 'OZ', 'O2', 'CB2', '0', '0']]\n",
    "\n",
    "channel_list = ['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2']\n",
    "print(len(channel_coords), len(channel_coords[0]))\n",
    "coord_dict = {}\n",
    "for n in range(len(channel_list)):\n",
    "    for i, l in enumerate(channel_coords):\n",
    "        for j, x in enumerate(l):\n",
    "            if (channel_list[n] == x):\n",
    "                coord_dict[n] = (i,j)\n",
    "print(coord_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/eeg_feature_smooth/1/\n",
      "./data/eeg_feature_smooth/2/\n",
      "./data/eeg_feature_smooth/3/\n",
      "(3, 15, 24, 4, 8, 9, 5, 64)\n"
     ]
    }
   ],
   "source": [
    "n = 24\n",
    "perSample = ['de_movingAve', 'de_LDS', 'psd_movingAve', 'psd_LDS']\n",
    "array = np.zeros(shape=(len(directories),len(os.listdir(directories[0])), n, 4, 8, 9, 5, 64)) # features = 4 datatypes*(8 x 9 eeg channel locs)*5 frequency bands*64 timestamps(zero padded) // trials = (3 sessions) x 15 people x 24 labels \n",
    "li = []\n",
    "for h, dire in enumerate(directories):\n",
    "    print(dire)\n",
    "    data = [loadmat(dire + file) for file in os.listdir(dire)]\n",
    "    for i, bigsample in enumerate(data):\n",
    "        for j in range(n):\n",
    "            for k, key in enumerate(perSample):\n",
    "                sample = np.transpose(np.array(bigsample[key + str(j+1)]), (0,2,1))\n",
    "                sample = np.pad(sample, [(0,0), (0,0), (0, 64-sample.shape[2])])\n",
    "                for l, channel in enumerate(sample):\n",
    "                    array[h][i][j][k][coord_dict[l][0]][coord_dict[l][1]] = channel\n",
    "\n",
    "print(array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 4, 8, 9, 5, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X = array.reshape(np.prod(array.shape[0:3]), *array.shape[3:])\n",
    "_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session1_label = [1,2,3,0,2,0,0,1,0,1,2,1,1,1,2,3,2,2,3,3,0,3,0,3]\n",
    "session2_label = [2,1,3,0,0,2,0,2,3,3,2,3,2,0,1,1,2,1,0,3,0,1,3,1]\n",
    "session3_label = [1,2,2,1,3,3,3,1,1,2,1,0,2,3,3,0,2,3,0,0,2,0,1,0]\n",
    "labels = {0: 'neutral', 1: 'sad', 2: 'fear', 3: 'happy'}\n",
    "\n",
    "y = np.array(session1_label * 15 + session2_label * 15 + session3_label * 15)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(generate_model, n_epochs, X_train, y_train, X_test, y_test, filename = None):\n",
    "    kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n",
    "    bestmodel = None\n",
    "    bestAcc = 0\n",
    "    cvscores = []\n",
    "    fold = 1\n",
    "    for train, test in kfold.split(X_train, y_train):\n",
    "        model = generate_model()\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold} ...')\n",
    "        model.fit(X_train[train], y_train[train],epochs=n_epochs, verbose=0, validation_split=0.2)\n",
    "        scores = model.evaluate(X_train[test], y_train[test], verbose=1)\n",
    "        print(\"Score for fold %d - %s: %.2f%%\" % (fold, model.metrics_names[1], scores[1]*100))\n",
    "        if(scores[1] > bestAcc):\n",
    "            bestAcc = scores[1]\n",
    "            bestmodel = model\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        fold += 1\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(\"Avg accuracies: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    test_loss, test_acc = bestmodel.evaluate(X_test,  y_test, verbose=2)\n",
    "    print('\\nTest accuracy:', test_acc)\n",
    "    if filename:\n",
    "        pickle.dump( bestmodel, open( filename, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_conv():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.SeparableConv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='relu',input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.SeparableConv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.SeparableConv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.SeparableConv1D(\n",
    "128, 3, data_format='channels_last', padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_conv():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(\n",
    "32, 3, activation='relu',input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(100),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twodConv():\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "32, 3, padding=\"same\", activation=\"relu\",input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.BatchNormalization(center=True, scale=True),\n",
    "    tf.keras.layers.Conv2D(\n",
    "64, 3, padding=\"same\", activation=\"relu\",input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=2, strides=2, data_format=\"channels_last\"),\n",
    "    tf.keras.layers.BatchNormalization(center=True, scale=True),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threedConv():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv3D(32, kernel_size=10, padding=\"same\", activation='relu', kernel_initializer='he_uniform', input_shape=X.shape[1:]))\n",
    "    model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    #model.add(tf.keras.layers.BatchNormalization())\n",
    "    #model.add(tf.keras.layers.Dropout(0.5))\n",
    "    #model.add(tf.keras.layers.Conv3D(64, kernel_size=3, activation='relu', padding=\"same\", kernel_initializer='he_uniform'))\n",
    "    #model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    #model.add(tf.keras.layers.BatchNormalization(center=True, scale=True))\n",
    "    #model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 4, 8, 9, 5)\n",
      "(1080, 64, 1440)\n"
     ]
    }
   ],
   "source": [
    "X = _X.transpose(0, 5, 1,2,3,4)\n",
    "print(X.shape)\n",
    "X = X.reshape(X.shape[0], X.shape[1], np.prod(X.shape[2:]))\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 132050960.0000 - accuracy: 0.5278\n",
      "Score for fold 1 - accuracy: 52.78%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 306641984.0000 - accuracy: 0.6019\n",
      "Score for fold 2 - accuracy: 60.19%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 900130176.0000 - accuracy: 0.4491\n",
      "Score for fold 3 - accuracy: 44.91%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 210064016.0000 - accuracy: 0.6065\n",
      "Score for fold 4 - accuracy: 60.65%\n",
      "------------------------------------------------------------------------\n",
      "Avg accuracies: 54.63% (+/- 6.42%)\n",
      "7/7 - 0s - loss: 572573120.0000 - accuracy: 0.5880\n",
      "\n",
      "Test accuracy: 0.5879629850387573\n"
     ]
    }
   ],
   "source": [
    "crossval(dense, 40, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 24415792.0000 - accuracy: 0.5139\n",
      "Score for fold 1 - accuracy: 51.39%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 287301024.0000 - accuracy: 0.4028\n",
      "Score for fold 2 - accuracy: 40.28%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 237452944.0000 - accuracy: 0.6620\n",
      "Score for fold 3 - accuracy: 66.20%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 220737200.0000 - accuracy: 0.4769\n",
      "Score for fold 4 - accuracy: 47.69%\n",
      "------------------------------------------------------------------------\n",
      "Avg accuracies: 51.39% (+/- 9.44%)\n",
      "7/7 - 0s - loss: 182980432.0000 - accuracy: 0.6296\n",
      "\n",
      "Test accuracy: 0.6296296119689941\n"
     ]
    }
   ],
   "source": [
    "crossval(single_conv, 40, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 8, 9, 10)\n"
     ]
    }
   ],
   "source": [
    "X = _X.transpose(0, 5, 2,3, 4, 1)[:,:,:,:,:,[0,2]]\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], X.shape[3], np.prod(X.shape[4:]))\n",
    "print(X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 394562272.0000 - accuracy: 0.5787\n",
      "Score for fold 1 - accuracy: 57.87%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 104632808.0000 - accuracy: 0.4861\n",
      "Score for fold 2 - accuracy: 48.61%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 5871898112.0000 - accuracy: 0.4676\n",
      "Score for fold 3 - accuracy: 46.76%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 340366336.0000 - accuracy: 0.5278\n",
      "Score for fold 4 - accuracy: 52.78%\n",
      "------------------------------------------------------------------------\n",
      "Avg accuracies: 51.50% (+/- 4.27%)\n",
      "7/7 - 0s - loss: 463900672.0000 - accuracy: 0.5926\n",
      "\n",
      "Test accuracy: 0.5925925970077515\n"
     ]
    }
   ],
   "source": [
    "crossval(threedConv, 100, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
