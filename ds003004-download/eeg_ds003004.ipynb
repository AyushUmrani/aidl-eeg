{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5324832403467358251\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17216283431940257085\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3993036413124878603\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7009469728\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6594558881444651297\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "import pandas\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "set_session(sess)\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/sub-01/eeg/sub-01_task-ImaginedEmotion_eeg.set', './data/sub-02/eeg/sub-02_task-ImaginedEmotion_eeg.set', './data/sub-03/eeg/sub-03_task-ImaginedEmotion_eeg.set', './data/sub-04/eeg/sub-04_task-ImaginedEmotion_eeg.set', './data/sub-05/eeg/sub-05_task-ImaginedEmotion_eeg.set', './data/sub-06/eeg/sub-06_task-ImaginedEmotion_eeg.set', './data/sub-07/eeg/sub-07_task-ImaginedEmotion_eeg.set', './data/sub-08/eeg/sub-08_task-ImaginedEmotion_eeg.set', './data/sub-09/eeg/sub-09_task-ImaginedEmotion_eeg.set', './data/sub-10/eeg/sub-10_task-ImaginedEmotion_eeg.set', './data/sub-11/eeg/sub-11_task-ImaginedEmotion_eeg.set', './data/sub-12/eeg/sub-12_task-ImaginedEmotion_eeg.set', './data/sub-13/eeg/sub-13_task-ImaginedEmotion_eeg.set', './data/sub-14/eeg/sub-14_task-ImaginedEmotion_eeg.set', './data/sub-15/eeg/sub-15_task-ImaginedEmotion_eeg.set', './data/sub-16/eeg/sub-16_task-ImaginedEmotion_eeg.set', './data/sub-17/eeg/sub-17_task-ImaginedEmotion_eeg.set', './data/sub-18/eeg/sub-18_task-ImaginedEmotion_eeg.set', './data/sub-19/eeg/sub-19_task-ImaginedEmotion_eeg.set', './data/sub-20/eeg/sub-20_task-ImaginedEmotion_eeg.set', './data/sub-21/eeg/sub-21_task-ImaginedEmotion_eeg.set', './data/sub-23/eeg/sub-23_task-ImaginedEmotion_eeg.set', './data/sub-24/eeg/sub-24_task-ImaginedEmotion_eeg.set', './data/sub-25/eeg/sub-25_task-ImaginedEmotion_eeg.set', './data/sub-26/eeg/sub-26_task-ImaginedEmotion_eeg.set', './data/sub-27/eeg/sub-27_task-ImaginedEmotion_eeg.set', './data/sub-28/eeg/sub-28_task-ImaginedEmotion_eeg.set', './data/sub-29/eeg/sub-29_task-ImaginedEmotion_eeg.set', './data/sub-30/eeg/sub-30_task-ImaginedEmotion_eeg.set', './data/sub-31/eeg/sub-31_task-ImaginedEmotion_eeg.set', './data/sub-32/eeg/sub-32_task-ImaginedEmotion_eeg.set', './data/sub-33/eeg/sub-33_task-ImaginedEmotion_eeg.set', './data/sub-34/eeg/sub-34_task-ImaginedEmotion_eeg.set', './data/sub-35/eeg/sub-35_task-ImaginedEmotion_eeg.set']\n"
     ]
    }
   ],
   "source": [
    "fnames = [\"./data/sub-{:02d}/eeg/sub-{:02d}_task-ImaginedEmotion_eeg.set\".format(i,i) for i in list(range(1,22)) + list(range(23,36))]\n",
    "print(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/sub-01/eeg/sub-01_task-ImaginedEmotion_eeg.set', './data/sub-02/eeg/sub-02_task-ImaginedEmotion_eeg.set', './data/sub-04/eeg/sub-04_task-ImaginedEmotion_eeg.set', './data/sub-05/eeg/sub-05_task-ImaginedEmotion_eeg.set', './data/sub-06/eeg/sub-06_task-ImaginedEmotion_eeg.set', './data/sub-08/eeg/sub-08_task-ImaginedEmotion_eeg.set', './data/sub-09/eeg/sub-09_task-ImaginedEmotion_eeg.set', './data/sub-10/eeg/sub-10_task-ImaginedEmotion_eeg.set', './data/sub-11/eeg/sub-11_task-ImaginedEmotion_eeg.set', './data/sub-12/eeg/sub-12_task-ImaginedEmotion_eeg.set', './data/sub-13/eeg/sub-13_task-ImaginedEmotion_eeg.set', './data/sub-14/eeg/sub-14_task-ImaginedEmotion_eeg.set', './data/sub-15/eeg/sub-15_task-ImaginedEmotion_eeg.set', './data/sub-16/eeg/sub-16_task-ImaginedEmotion_eeg.set', './data/sub-17/eeg/sub-17_task-ImaginedEmotion_eeg.set', './data/sub-18/eeg/sub-18_task-ImaginedEmotion_eeg.set', './data/sub-19/eeg/sub-19_task-ImaginedEmotion_eeg.set', './data/sub-20/eeg/sub-20_task-ImaginedEmotion_eeg.set', './data/sub-21/eeg/sub-21_task-ImaginedEmotion_eeg.set', './data/sub-25/eeg/sub-25_task-ImaginedEmotion_eeg.set', './data/sub-26/eeg/sub-26_task-ImaginedEmotion_eeg.set', './data/sub-27/eeg/sub-27_task-ImaginedEmotion_eeg.set', './data/sub-28/eeg/sub-28_task-ImaginedEmotion_eeg.set', './data/sub-29/eeg/sub-29_task-ImaginedEmotion_eeg.set', './data/sub-30/eeg/sub-30_task-ImaginedEmotion_eeg.set', './data/sub-31/eeg/sub-31_task-ImaginedEmotion_eeg.set', './data/sub-32/eeg/sub-32_task-ImaginedEmotion_eeg.set', './data/sub-33/eeg/sub-33_task-ImaginedEmotion_eeg.set', './data/sub-34/eeg/sub-34_task-ImaginedEmotion_eeg.set', './data/sub-35/eeg/sub-35_task-ImaginedEmotion_eeg.set']\n"
     ]
    }
   ],
   "source": [
    "emotions = [\"prebase\", \"awe\", \"frustration\", \"joy\", \"anger\", \"happy\", \"sad\", \"love\", \"grief\", \"compassion\", \"fear\", \"content\", \"jealousy\", \"relief\", \"disgust\", \"excite\"]\n",
    "emotions_dict = {emotions[x]:x for x in range(len(emotions))}\n",
    "cleaned_files = fnames[0:2] +fnames[3:6] + fnames[7:21] + fnames[23:]\n",
    "print(cleaned_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/sub-01/eeg/sub-01_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-02/eeg/sub-02_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-04/eeg/sub-04_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-05/eeg/sub-05_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-06/eeg/sub-06_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-08/eeg/sub-08_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-09/eeg/sub-09_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-10/eeg/sub-10_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-11/eeg/sub-11_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-12/eeg/sub-12_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-13/eeg/sub-13_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-14/eeg/sub-14_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-15/eeg/sub-15_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-16/eeg/sub-16_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-17/eeg/sub-17_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-18/eeg/sub-18_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-19/eeg/sub-19_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-20/eeg/sub-20_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Reading ./data/sub-21/eeg/sub-21_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-25/eeg/sub-25_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-26/eeg/sub-26_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-27/eeg/sub-27_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-28/eeg/sub-28_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-29/eeg/sub-29_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-30/eeg/sub-30_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-31/eeg/sub-31_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-32/eeg/sub-32_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-33/eeg/sub-33_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-34/eeg/sub-34_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-35/eeg/sub-35_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "def get_min_durs(file):\n",
    "    patient = mne.io.read_raw_eeglab(file)\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(patient)\n",
    "    indices = []\n",
    "    for x in range(len(patient.annotations.description)):\n",
    "        if patient.annotations.description[x] in emotions:\n",
    "            indices.append(x)\n",
    "\n",
    "    num_events = len(events_from_annot)\n",
    "\n",
    "    for x in range(num_events):\n",
    "        if x in indices:\n",
    "            if indices.index(x) < len(indices) - 1:\n",
    "                y = indices[indices.index(x) + 1]\n",
    "                events_from_annot[x][1] = (events_from_annot[y - 2][0] - events_from_annot[x][0]) / 256\n",
    "                events_from_annot[x][0] /= 256\n",
    "            else:\n",
    "                print(indices.index(x))\n",
    "                y = num_events - 1\n",
    "                events_from_annot[x][1] = (events_from_annot[y - 2][0] - events_from_annot[x][0]) / 256\n",
    "                events_from_annot[x][0] /= 256\n",
    "\n",
    "    not_ind = []\n",
    "    for x in range(num_events):\n",
    "        if x not in indices:\n",
    "            not_ind.append(x)\n",
    "\n",
    "    events_from_annot = np.delete(events_from_annot, not_ind, axis=0)\n",
    "    onsets = events_from_annot[:, 0] \n",
    "    durations = events_from_annot[:, 1] \n",
    "    return min(durations)\n",
    "\n",
    "min_dur = min([get_min_durs(file) for file in cleaned_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/sub-01/eeg/sub-01_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-02/eeg/sub-02_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-04/eeg/sub-04_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-05/eeg/sub-05_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-06/eeg/sub-06_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-08/eeg/sub-08_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-09/eeg/sub-09_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-10/eeg/sub-10_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-11/eeg/sub-11_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-12/eeg/sub-12_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-13/eeg/sub-13_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-14/eeg/sub-14_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-15/eeg/sub-15_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-16/eeg/sub-16_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-17/eeg/sub-17_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-18/eeg/sub-18_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-19/eeg/sub-19_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-20/eeg/sub-20_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Reading ./data/sub-21/eeg/sub-21_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-25/eeg/sub-25_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-26/eeg/sub-26_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-27/eeg/sub-27_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-28/eeg/sub-28_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-29/eeg/sub-29_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-30/eeg/sub-30_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-31/eeg/sub-31_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-32/eeg/sub-32_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-33/eeg/sub-33_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-34/eeg/sub-34_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Reading ./data/sub-35/eeg/sub-35_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "def get_channels(file):\n",
    "    patient = mne.io.read_raw_eeglab(file)\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(patient)\n",
    "    indices = []\n",
    "    for x in range(len(patient.annotations.description)):\n",
    "        if patient.annotations.description[x] in emotions:\n",
    "            indices.append(x)\n",
    "\n",
    "    num_events = len(events_from_annot)\n",
    "\n",
    "    for x in range(num_events):\n",
    "        if x in indices:\n",
    "            if indices.index(x) < len(indices) - 1:\n",
    "                y = indices[indices.index(x) + 1]\n",
    "                events_from_annot[x][1] = (events_from_annot[y - 2][0] - events_from_annot[x][0]) / 256\n",
    "                events_from_annot[x][0] /= 256\n",
    "            else:\n",
    "                print(indices.index(x))\n",
    "                y = num_events - 1\n",
    "                events_from_annot[x][1] = (events_from_annot[y - 2][0] - events_from_annot[x][0]) / 256\n",
    "                events_from_annot[x][0] /= 256\n",
    "\n",
    "    not_ind = []\n",
    "    for x in range(num_events):\n",
    "        if x not in indices:\n",
    "            not_ind.append(x)\n",
    "\n",
    "    events_from_annot = np.delete(events_from_annot, not_ind, axis=0)\n",
    "    onsets = events_from_annot[:, 0] \n",
    "    durations = events_from_annot[:, 1] \n",
    "    mapping = {event_dict[x]: x for x in event_dict.keys()}\n",
    "    descriptions = [mapping[event_id] for event_id in events_from_annot[:, 2]]\n",
    "    annot_from_events = mne.Annotations(onset=onsets, duration=durations,\n",
    "                                    description=descriptions,\n",
    "                                    orig_time=patient.info['meas_date'])\n",
    "    patient.set_annotations(annot_from_events)\n",
    "    return patient.ch_names\n",
    "\n",
    "channels = [set(get_channels(file)) for file in cleaned_files]\n",
    "intersect = channels[0]\n",
    "\n",
    "for channel in channels:\n",
    "    intersect.intersection_update(channel)\n",
    "\n",
    "intersect = list(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "['B11', 'B12', 'F6', 'A10', 'F8', 'F16', 'B22', 'B29', 'B18', 'F17', 'F21', 'C14', 'B8', 'F7', 'F26', 'H3', 'B3', 'A4', 'B6', 'B24', 'C20']\n"
     ]
    }
   ],
   "source": [
    "print(min_dur)\n",
    "print(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(file, epoch_duration, channel_list):\n",
    "    patient = mne.io.read_raw_eeglab(file)\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(patient)\n",
    "    indices = []\n",
    "    for x in range(len(patient.annotations.description)):\n",
    "        if patient.annotations.description[x] in emotions:\n",
    "            indices.append(x)\n",
    "\n",
    "    num_events = len(events_from_annot)\n",
    "\n",
    "    for x in range(num_events):\n",
    "        if x in indices:\n",
    "            if indices.index(x) < len(indices) - 1:\n",
    "                y = indices[indices.index(x) + 1]\n",
    "                events_from_annot[x][1] = (events_from_annot[y - 2][0] - events_from_annot[x][0]) / 256\n",
    "                events_from_annot[x][0] /= 256\n",
    "            else:\n",
    "                print(indices.index(x))\n",
    "                y = num_events - 1\n",
    "                events_from_annot[x][1] = (events_from_annot[y - 2][0] - events_from_annot[x][0]) / 256\n",
    "                events_from_annot[x][0] /= 256\n",
    "\n",
    "    not_ind = []\n",
    "    for x in range(num_events):\n",
    "        if x not in indices:\n",
    "            not_ind.append(x)\n",
    "\n",
    "    events_from_annot = np.delete(events_from_annot, not_ind, axis=0)\n",
    "    onsets = events_from_annot[:, 0] \n",
    "    durations = events_from_annot[:, 1] \n",
    "    mapping = {event_dict[x]: x for x in event_dict.keys()}\n",
    "    descriptions = [mapping[event_id] for event_id in events_from_annot[:, 2]]\n",
    "    annot_from_events = mne.Annotations(onset=onsets, duration=durations,\n",
    "                                    description=descriptions,\n",
    "                                    orig_time=patient.info['meas_date'])\n",
    "    patient.set_annotations(annot_from_events)\n",
    "    descrip = patient.annotations.description\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(patient)\n",
    "    epochs = mne.Epochs(patient, events_from_annot, event_dict, picks=channel_list, tmin=0, tmax=epoch_duration, baseline=(None,None), on_missing=\"warning\", preload=True, reject_by_annotation=False)\n",
    "    del patient\n",
    "    #return epochs\n",
    "    data = epochs.get_data()\n",
    "    del epochs\n",
    "    return data, descrip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient1 = get_epochs(fnames[0])\n",
    "# patient1.plot_sensors(show_names=True)\n",
    "# patient2 = get_epochs(fnames[1])\n",
    "# patient2.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/sub-01/eeg/sub-01_task-ImaginedEmotion_eeg.set 1\n",
      "Reading ./data/sub-01/eeg/sub-01_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'frustration' 'joy' 'anger' 'happy' 'sad' 'love' 'grief'\n",
      " 'compassion' 'fear' 'content' 'jealousy' 'relief' 'disgust' 'excite']\n",
      "./data/sub-02/eeg/sub-02_task-ImaginedEmotion_eeg.set 2\n",
      "Reading ./data/sub-02/eeg/sub-02_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'frustration' 'joy' 'anger' 'happy' 'sad' 'love' 'grief'\n",
      " 'compassion' 'fear' 'content' 'jealousy' 'relief' 'disgust' 'excite']\n",
      "./data/sub-04/eeg/sub-04_task-ImaginedEmotion_eeg.set 3\n",
      "Reading ./data/sub-04/eeg/sub-04_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'happy' 'fear' 'awe' 'disgust' 'relief' 'jealousy' 'excite'\n",
      " 'frustration' 'content' 'anger' 'love' 'grief' 'joy' 'sad' 'compassion']\n",
      "./data/sub-05/eeg/sub-05_task-ImaginedEmotion_eeg.set 4\n",
      "Reading ./data/sub-05/eeg/sub-05_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'fear' 'joy' 'jealousy' 'excite' 'disgust' 'love' 'grief'\n",
      " 'content' 'frustration' 'happy' 'anger' 'relief' 'sad' 'compassion']\n",
      "./data/sub-06/eeg/sub-06_task-ImaginedEmotion_eeg.set 5\n",
      "Reading ./data/sub-06/eeg/sub-06_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'love' 'grief' 'awe' 'frustration' 'happy' 'jealousy' 'excite'\n",
      " 'disgust' 'relief' 'sad' 'content' 'anger' 'compassion' 'fear' 'joy']\n",
      "./data/sub-08/eeg/sub-08_task-ImaginedEmotion_eeg.set 6\n",
      "Reading ./data/sub-08/eeg/sub-08_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'fear' 'joy' 'jealousy' 'excite' 'disgust' 'love' 'grief'\n",
      " 'content' 'frustration' 'happy' 'anger' 'relief' 'sad' 'compassion']\n",
      "./data/sub-09/eeg/sub-09_task-ImaginedEmotion_eeg.set 7\n",
      "Reading ./data/sub-09/eeg/sub-09_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'compassion' 'grief' 'relief' 'anger' 'content' 'sad' 'love'\n",
      " 'frustration' 'excite' 'fear' 'happy' 'jealousy' 'joy' 'disgust' 'awe']\n",
      "./data/sub-10/eeg/sub-10_task-ImaginedEmotion_eeg.set 8\n",
      "Reading ./data/sub-10/eeg/sub-10_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'happy' 'fear' 'awe' 'disgust' 'relief' 'jealousy' 'excite'\n",
      " 'frustration' 'content' 'anger' 'love' 'grief' 'joy' 'sad' 'compassion']\n",
      "./data/sub-11/eeg/sub-11_task-ImaginedEmotion_eeg.set 9\n",
      "Reading ./data/sub-11/eeg/sub-11_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'love' 'grief' 'awe' 'frustration' 'happy' 'jealousy' 'excite'\n",
      " 'disgust' 'relief' 'sad' 'content' 'anger' 'compassion' 'fear' 'joy']\n",
      "./data/sub-12/eeg/sub-12_task-ImaginedEmotion_eeg.set 10\n",
      "Reading ./data/sub-12/eeg/sub-12_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'fear' 'joy' 'jealousy' 'excite' 'disgust' 'love' 'grief'\n",
      " 'content' 'frustration' 'happy' 'anger' 'relief' 'sad' 'compassion']\n",
      "./data/sub-13/eeg/sub-13_task-ImaginedEmotion_eeg.set 11\n",
      "Reading ./data/sub-13/eeg/sub-13_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'compassion' 'grief' 'relief' 'anger' 'content' 'sad' 'love'\n",
      " 'frustration' 'excite' 'fear' 'happy' 'jealousy' 'joy' 'disgust' 'awe']\n",
      "./data/sub-14/eeg/sub-14_task-ImaginedEmotion_eeg.set 12\n",
      "Reading ./data/sub-14/eeg/sub-14_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'compassion' 'grief' 'relief' 'anger' 'content' 'sad' 'love'\n",
      " 'frustration' 'excite' 'fear' 'happy' 'jealousy' 'joy' 'disgust' 'awe']\n",
      "./data/sub-15/eeg/sub-15_task-ImaginedEmotion_eeg.set 13\n",
      "Reading ./data/sub-15/eeg/sub-15_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'love' 'grief' 'awe' 'frustration' 'happy' 'jealousy' 'excite'\n",
      " 'disgust' 'relief' 'sad' 'content' 'anger' 'compassion' 'fear' 'joy']\n",
      "./data/sub-16/eeg/sub-16_task-ImaginedEmotion_eeg.set 14\n",
      "Reading ./data/sub-16/eeg/sub-16_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'frustration' 'joy' 'anger' 'happy' 'sad' 'love' 'fear'\n",
      " 'compassion' 'jealousy' 'content' 'grief' 'relief' 'disgust' 'excite']\n",
      "./data/sub-17/eeg/sub-17_task-ImaginedEmotion_eeg.set 15\n",
      "Reading ./data/sub-17/eeg/sub-17_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'happy' 'fear' 'awe' 'disgust' 'relief' 'jealousy' 'excite'\n",
      " 'frustration' 'content' 'anger' 'love' 'grief' 'joy' 'sad' 'compassion']\n",
      "./data/sub-18/eeg/sub-18_task-ImaginedEmotion_eeg.set 16\n",
      "Reading ./data/sub-18/eeg/sub-18_task-ImaginedEmotion_eeg.fdt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'fear' 'joy' 'jealousy' 'excite' 'disgust' 'love' 'grief'\n",
      " 'content' 'frustration' 'happy' 'anger' 'relief' 'sad' 'compassion']\n",
      "./data/sub-19/eeg/sub-19_task-ImaginedEmotion_eeg.set 17\n",
      "Reading ./data/sub-19/eeg/sub-19_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'frustration' 'joy' 'anger' 'happy' 'sad' 'love' 'fear'\n",
      " 'compassion' 'jealousy' 'content' 'grief' 'relief' 'disgust' 'excite']\n",
      "./data/sub-20/eeg/sub-20_task-ImaginedEmotion_eeg.set 18\n",
      "Reading ./data/sub-20/eeg/sub-20_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'compassion' 'grief' 'relief' 'anger' 'content' 'sad' 'love'\n",
      " 'frustration' 'excite' 'fear' 'happy' 'jealousy' 'joy' 'disgust' 'awe']\n",
      "./data/sub-21/eeg/sub-21_task-ImaginedEmotion_eeg.set 19\n",
      "Reading ./data/sub-21/eeg/sub-21_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'frustration' 'joy' 'anger' 'happy' 'sad' 'love' 'fear'\n",
      " 'compassion' 'jealousy' 'content' 'grief' 'relief' 'disgust' 'excite']\n",
      "./data/sub-25/eeg/sub-25_task-ImaginedEmotion_eeg.set 20\n",
      "Reading ./data/sub-25/eeg/sub-25_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'happy' 'fear' 'awe' 'disgust' 'relief' 'jealousy' 'excite'\n",
      " 'frustration' 'content' 'anger' 'love' 'grief' 'joy' 'sad' 'compassion']\n",
      "./data/sub-26/eeg/sub-26_task-ImaginedEmotion_eeg.set 21\n",
      "Reading ./data/sub-26/eeg/sub-26_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'fear' 'joy' 'jealousy' 'excite' 'disgust' 'love' 'grief'\n",
      " 'content' 'frustration' 'happy' 'anger' 'relief' 'sad' 'compassion']\n",
      "./data/sub-27/eeg/sub-27_task-ImaginedEmotion_eeg.set 22\n",
      "Reading ./data/sub-27/eeg/sub-27_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'compassion' 'grief' 'relief' 'anger' 'content' 'sad' 'love'\n",
      " 'frustration' 'excite' 'fear' 'happy' 'jealousy' 'joy' 'disgust' 'awe']\n",
      "./data/sub-28/eeg/sub-28_task-ImaginedEmotion_eeg.set 23\n",
      "Reading ./data/sub-28/eeg/sub-28_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'fear' 'joy' 'jealousy' 'excite' 'disgust' 'love' 'grief'\n",
      " 'content' 'frustration' 'happy' 'anger' 'relief' 'sad' 'compassion']\n",
      "./data/sub-29/eeg/sub-29_task-ImaginedEmotion_eeg.set 24\n",
      "Reading ./data/sub-29/eeg/sub-29_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'frustration' 'joy' 'anger' 'happy' 'sad' 'love' 'fear'\n",
      " 'compassion' 'jealousy' 'content' 'grief' 'relief' 'disgust' 'excite']\n",
      "./data/sub-30/eeg/sub-30_task-ImaginedEmotion_eeg.set 25\n",
      "Reading ./data/sub-30/eeg/sub-30_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'happy' 'fear' 'awe' 'disgust' 'relief' 'jealousy' 'excite'\n",
      " 'frustration' 'content' 'anger' 'love' 'grief' 'joy' 'sad' 'compassion']\n",
      "./data/sub-31/eeg/sub-31_task-ImaginedEmotion_eeg.set 26\n",
      "Reading ./data/sub-31/eeg/sub-31_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'compassion' 'grief' 'relief' 'anger' 'content' 'sad' 'love'\n",
      " 'frustration' 'excite' 'fear' 'happy' 'jealousy' 'joy' 'disgust' 'awe']\n",
      "./data/sub-32/eeg/sub-32_task-ImaginedEmotion_eeg.set 27\n",
      "Reading ./data/sub-32/eeg/sub-32_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'love' 'grief' 'awe' 'frustration' 'happy' 'jealousy' 'excite'\n",
      " 'disgust' 'relief' 'sad' 'content' 'anger' 'compassion' 'fear' 'joy']\n",
      "./data/sub-33/eeg/sub-33_task-ImaginedEmotion_eeg.set 28\n",
      "Reading ./data/sub-33/eeg/sub-33_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'happy' 'fear' 'awe' 'disgust' 'relief' 'jealousy' 'excite'\n",
      " 'frustration' 'content' 'anger' 'love' 'grief' 'joy' 'sad' 'compassion']\n",
      "./data/sub-34/eeg/sub-34_task-ImaginedEmotion_eeg.set 29\n",
      "Reading ./data/sub-34/eeg/sub-34_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'awe' 'fear' 'joy' 'jealousy' 'excite' 'disgust' 'love' 'grief'\n",
      " 'content' 'frustration' 'happy' 'anger' 'relief' 'sad' 'compassion']\n",
      "./data/sub-35/eeg/sub-35_task-ImaginedEmotion_eeg.set 30\n",
      "Reading ./data/sub-35/eeg/sub-35_task-ImaginedEmotion_eeg.fdt\n",
      "Used Annotations descriptions: ['ExitThankYou', 'FeelingItInstructionsNoButton', 'ImaginationSuggestions', 'InitialInstructions', 'InstructionsForEnding', 'anger', 'awe', 'compassion', 'content', 'disgust', 'enter', 'excite', 'exit', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'postbase', 'postbase_instruct', 'prebase', 'prebase_instruct', 'press1', 'relax', 'relief', 'sad']\n",
      "15\n",
      "Used Annotations descriptions: ['anger', 'awe', 'compassion', 'content', 'disgust', 'excite', 'fear', 'frustration', 'grief', 'happy', 'jealousy', 'joy', 'love', 'prebase', 'relief', 'sad']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 16 events and 17409 original time points ...\n",
      "0 bad epochs dropped\n",
      "(16, 21, 17409) ['prebase' 'love' 'grief' 'awe' 'frustration' 'happy' 'jealousy' 'excite'\n",
      " 'disgust' 'relief' 'sad' 'content' 'anger' 'compassion' 'fear' 'joy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 21, 17409)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "descrip = []\n",
    "i = 0\n",
    "for file in cleaned_files:\n",
    "    i += 1 \n",
    "    print(file, i)\n",
    "    data_file, descrip_file = get_data(file, min_dur, intersect)\n",
    "    print(data_file.shape, descrip_file)\n",
    "    for x in range(data_file.shape[0]):\n",
    "        data.append(data_file[x])\n",
    "        descrip.append(descrip_file[x])\n",
    "        \n",
    "data = np.asarray(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 21, 17409)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(data)\n",
    "print(data.shape)\n",
    "labels = []\n",
    "for x in np.asarray([emotions_dict[x] for x in descrip]):\n",
    "    ar = np.zeros(16)\n",
    "    ar[x] = 1\n",
    "    labels.append(ar)\n",
    "    \n",
    "labels = np.asarray(labels)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Lambda\n",
    "from tensorflow.keras.layers import DepthwiseConv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.layers import SeparableConv1D \n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "\n",
    "def TA_CSPNN(nb_classes, Channels = 64, Timesamples = 90, \n",
    "             dropOut = 0.25,  timeKernelLen = 100, Ft = 22, Fs = 6):\n",
    "    \n",
    "    # Input shape is (trials, 1, number of channels, number of time samples)\n",
    "\n",
    "    input_e      = Input(shape = (1, Channels, Timesamples))    \n",
    "    convL1       = Conv2D(Ft, (1, timeKernelLen), padding = 'same',input_shape = (1, Channels, Timesamples), use_bias = False)(input_e)\n",
    "\n",
    "    bNorm1       = BatchNormalization(axis = 1)(convL1)\n",
    "\n",
    "    convL2       = DepthwiseConv2D((Channels, 1), use_bias = False, \n",
    "                                   depth_multiplier = Fs, depthwise_constraint = max_norm(1.))(bNorm1)  \n",
    "    bNorm2       = BatchNormalization(axis = 1)(convL2)\n",
    "    \n",
    "    lambdaL      = Lambda(lambda x:x**2)(bNorm2)\n",
    "    aPool        = AveragePooling2D((1, Timesamples))(lambdaL)\n",
    "\n",
    "    dOutL       = Dropout(dropOut)(aPool)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(dOutL)\n",
    "\n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_e, outputs=softmax)\n",
    "\n",
    "\n",
    "def onedcnn(nb_classes, Channels, Timesamples):\n",
    "    \n",
    "    # Input shape is (trials, 1, number of channels, number of time samples)\n",
    "\n",
    "    input_e      = Input(shape = (Channels, Timesamples))    \n",
    "    convL1       = SeparableConv1D(32, 256, padding = 'same',activation=\"relu\", input_shape = (Channels,Timesamples), data_format=\"channels_first\")(input_e)\n",
    "    pool         = tf.keras.layers.MaxPooling1D(60, data_format=\"channels_first\")(convL1)\n",
    "\n",
    "    flatten      = Flatten(name = 'flatten')(pool)\n",
    "\n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_e, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "def rnn(nb_classes, Timesamples, Channels):\n",
    "\n",
    "    input_e = Input(shape = (Timesamples, Channels))\n",
    "    gru     = tf.keras.layers.GRU(100)(input_e)\n",
    "    dense   = Dense(nb_classes, activation=\"softmax\")(gru)\n",
    "    softmax = Activation('softmax', name = 'softmax')(dense)\n",
    "    return Model(inputs = input_e, outpus=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1dp2(num_classes, input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", data_format='channels_first')(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", data_format='channels_first')(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", data_format='channels_first')(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 60 from 21 for '{{node max_pooling1d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 60, 1], padding=\"VALID\", strides=[1, 1, 60, 1]](max_pooling1d_2/ExpandDims)' with input shapes: [?,32,21,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1794\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 60 from 21 for '{{node max_pooling1d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 60, 1], padding=\"VALID\", strides=[1, 1, 60, 1]](max_pooling1d_2/ExpandDims)' with input shapes: [?,32,21,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c6769b43d973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monedcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimesamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e292624f52d1>\u001b[0m in \u001b[0;36monedcnn\u001b[0;34m(nb_classes, Channels, Timesamples)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0minput_e\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimesamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mconvL1\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mSeparableConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTimesamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_first\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mpool\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_first\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvL1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mflatten\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'flatten'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    931\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         data_format=self.data_format)\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     x = nn.max_pool(\n\u001b[0;32m-> 5404\u001b[0;31m         x, pool_size, strides, padding=padding, data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   5405\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m     x = nn.avg_pool(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5254\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m   5255\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5256\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5257\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3466\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3468\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3469\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3470\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1958\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1959\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1796\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 60 from 21 for '{{node max_pooling1d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 60, 1], padding=\"VALID\", strides=[1, 1, 60, 1]](max_pooling1d_2/ExpandDims)' with input shapes: [?,32,21,1]."
     ]
    }
   ],
   "source": [
    "data2 = np.transpose(data, axes=(0,2,1))\n",
    "\n",
    "data = data2\n",
    "shape = data.shape\n",
    "cnn = onedcnn(16, Channels = shape[1], Timesamples = shape[2])\n",
    "cnn.summary()\n",
    "\n",
    "\n",
    "cnn2 = conv1dp2(16, shape[1:])\n",
    "cnn2.summary()\n",
    "\n",
    "print(shape)\n",
    "rnn = rnn(16, shape[1], shape[2])\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 17409, 21)\n",
      "(300, 16)\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 21, 17409) for input Tensor(\"input_5:0\", shape=(None, 21, 17409), dtype=float32), but it was called on an input with incompatible shape (10, 17409, 21).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:630 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:620 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:952 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2292 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2651 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:613 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:937 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:896 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer conv1d_3 is incompatible with the layer: expected axis 1 of input shape to have value 21 but received input with shape [10, 17409, 21]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-28ea47709bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# fit the keras model on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    919\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    533\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    534\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 535\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2774\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2664\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2665\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:630 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:620 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:952 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2292 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2651 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:613 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:937 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:896 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer conv1d_3 is incompatible with the layer: expected axis 1 of input shape to have value 21 but received input with shape [10, 17409, 21]\n"
     ]
    }
   ],
   "source": [
    "cnn2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "X_train = data[:300]\n",
    "X_test = data[300:]\n",
    "y_train = labels[:300]\n",
    "y_test = labels[300:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "cnn2.fit(X_train, y_train, epochs=15, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = cnn2.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
